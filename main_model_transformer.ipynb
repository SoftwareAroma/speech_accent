{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\musah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import keras\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import warnings\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATE_HZ = 16000 # resampling rate in Hz\n",
    "MAX_LENGTH = 128000 # maximum audio interval length to consider (= RATE_HZ * SECONDS)\n",
    "CSV_FILE_PATH: str = \"bio_metadata.csv\"\n",
    "NATIVE_FILE_PATH: str = \"native_bio_metadata.csv\"\n",
    "ALL_SPEAKERS_PATH: str = \"speakers_all.csv\"\n",
    "NON_NATIVE_FILE_PATH: str = \"non_native_bio_metadata.csv\"\n",
    "COL_SIZE: int = 30\n",
    "SILENCE_THRESHOLD: float = .01\n",
    "RATE: int = 2400\n",
    "N_MFCC: int = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract acoustic features from audio files function\n",
    "def extract_mfcc_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=N_MFCC)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "    return mfccs_processed\n",
    "\n",
    "# extract, chroma_stft, spectral_centroid, \n",
    "# spectral_bandwidth, spectral_rolloff, zero_crossing_rate function\n",
    "def extract_accoustic_features(file_name):\n",
    "    \"\"\"\n",
    "        Extracts accoustic features from audio file\n",
    "        Takes in the file name and returns the following features:\n",
    "        Args:\n",
    "            :param file_name: str: name of the file to extract features from\n",
    "        Returns:\n",
    "            :return mfcc: np.array: Mel-frequency cepstral coefficients\n",
    "            :return chroma_stft: np.array: Chroma short-time Fourier transform\n",
    "            :return spectral_centroid: np.array: Spectral centroid\n",
    "            :return spectral_bandwidth: np.array: Spectral bandwidth\n",
    "            :return spectral_rolloff: np.array: Spectral rolloff\n",
    "            :return zero_crossing_rate: np.array: Zero crossing rate\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(f'./data/audio/{file_name}')\n",
    "        mfcc = np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=COL_SIZE).T, axis=0)\n",
    "        chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate).T, axis=0)\n",
    "        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sample_rate).T, axis=0)\n",
    "        spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=audio, sr=sample_rate).T, axis=0)\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sample_rate).T, axis=0)\n",
    "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(audio).T, axis=0)\n",
    "        return mfcc, chroma_stft, spectral_centroid, spectral_bandwidth, spectral_rolloff, zero_crossing_rate\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "    \n",
    "\n",
    "# extract pitch intensity, duration, loudness, jitter, shimmer, hnr function (prosodic features)\n",
    "def extract_prosodic_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        pitch_intensity = np.mean(librosa.pyin.piptrack(y=audio, sr=sample_rate).T, axis=0)\n",
    "        duration = np.mean(librosa.effects.time_stretch(audio, 1.0).T, axis=0)\n",
    "        loudness = np.mean(librosa.feature.rms(y=audio).T, axis=0)\n",
    "        jitter = np.mean(librosa.effects.jitter(y=audio).T, axis=0)\n",
    "        shimmer = np.mean(librosa.effects.shimmer(y=audio).T, axis=0)\n",
    "        hnr = np.mean(librosa.effects.harmonic(y=audio).T, axis=0)\n",
    "        return pitch_intensity, duration, loudness, jitter, shimmer, hnr\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "    \n",
    "\n",
    "# extract plp features function\n",
    "def extract_plp_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        plp = np.mean(librosa.beat.plp(y=audio, sr=sample_rate, n_mfcc=COL_SIZE).T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "    return plp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wav from file function\n",
    "def get_wav(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(f'./data/audio/{file_name}.wav')\n",
    "        return librosa.core.resample(y=audio, orig_sr=sample_rate, target_sr=RATE, scale=True)\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None\n",
    "\n",
    "# convert wave to mfcc function\n",
    "def wave_to_mfcc(audio, sample_rate):\n",
    "    try:\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=N_MFCC)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing audio\")\n",
    "        return None\n",
    "    return mfccs_processed\n",
    "\n",
    "# normalize mfcc function\n",
    "def normalize_mfcc(mfcc):\n",
    "    mms = MinMaxScaler()\n",
    "    return mms.fit_transform(np.abs(mfcc))\n",
    "\n",
    "# to categorical function\n",
    "def to_categorical(y):\n",
    "    lang_dict = {}\n",
    "    for index, language in enumerate(set(y)):\n",
    "        lang_dict[language] = index\n",
    "    y = list(map(lambda x: lang_dict[x],y))\n",
    "    return keras.utils.to_categorical(y, len(lang_dict)), lang_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "      <th>language_num</th>\n",
       "      <th>sex</th>\n",
       "      <th>birth_place</th>\n",
       "      <th>native_language</th>\n",
       "      <th>other_languages</th>\n",
       "      <th>age_sex</th>\n",
       "      <th>age_of_english_onset</th>\n",
       "      <th>english_learning_method</th>\n",
       "      <th>english_residence</th>\n",
       "      <th>length_of_english_residence</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://accent.gmu.edu/browse_language.php?func...</td>\n",
       "      <td>mandarin1</td>\n",
       "      <td>female</td>\n",
       "      <td>['shanxi,', 'china']</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>['none']</td>\n",
       "      <td>['26,', 'female', '']</td>\n",
       "      <td>13.0</td>\n",
       "      <td>academic</td>\n",
       "      <td>usa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://accent.gmu.edu/browse_language.php?func...</td>\n",
       "      <td>mandarin2</td>\n",
       "      <td>female</td>\n",
       "      <td>['nanjing,', 'china']</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>['japanese', '']</td>\n",
       "      <td>['38,', 'female', '']</td>\n",
       "      <td>14.0</td>\n",
       "      <td>academic</td>\n",
       "      <td>usa</td>\n",
       "      <td>0.8</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://accent.gmu.edu/browse_language.php?func...</td>\n",
       "      <td>mandarin3</td>\n",
       "      <td>male</td>\n",
       "      <td>['jilin,', 'china']</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>['italian', 'german', 'french', '']</td>\n",
       "      <td>['43,', 'male', '']</td>\n",
       "      <td>10.0</td>\n",
       "      <td>academic</td>\n",
       "      <td>usa</td>\n",
       "      <td>14.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://accent.gmu.edu/browse_language.php?func...</td>\n",
       "      <td>mandarin4</td>\n",
       "      <td>female</td>\n",
       "      <td>['shanghai,', 'china']</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>['japanese', '']</td>\n",
       "      <td>['24,', 'female', '']</td>\n",
       "      <td>6.0</td>\n",
       "      <td>academic</td>\n",
       "      <td>usa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://accent.gmu.edu/browse_language.php?func...</td>\n",
       "      <td>mandarin5</td>\n",
       "      <td>female</td>\n",
       "      <td>['beijing,', 'china']</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>['none']</td>\n",
       "      <td>['31,', 'female', '']</td>\n",
       "      <td>12.0</td>\n",
       "      <td>academic</td>\n",
       "      <td>usa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                href language_num     sex  \\\n",
       "0  http://accent.gmu.edu/browse_language.php?func...    mandarin1  female   \n",
       "1  http://accent.gmu.edu/browse_language.php?func...    mandarin2  female   \n",
       "2  http://accent.gmu.edu/browse_language.php?func...    mandarin3    male   \n",
       "3  http://accent.gmu.edu/browse_language.php?func...    mandarin4  female   \n",
       "4  http://accent.gmu.edu/browse_language.php?func...    mandarin5  female   \n",
       "\n",
       "              birth_place  native_language  \\\n",
       "0    ['shanxi,', 'china']  mandarin\\n(cmn)   \n",
       "1   ['nanjing,', 'china']  mandarin\\n(cmn)   \n",
       "2     ['jilin,', 'china']  mandarin\\n(cmn)   \n",
       "3  ['shanghai,', 'china']  mandarin\\n(cmn)   \n",
       "4   ['beijing,', 'china']  mandarin\\n(cmn)   \n",
       "\n",
       "                       other_languages                age_sex  \\\n",
       "0                             ['none']  ['26,', 'female', '']   \n",
       "1                     ['japanese', '']  ['38,', 'female', '']   \n",
       "2  ['italian', 'german', 'french', '']    ['43,', 'male', '']   \n",
       "3                     ['japanese', '']  ['24,', 'female', '']   \n",
       "4                             ['none']  ['31,', 'female', '']   \n",
       "\n",
       "   age_of_english_onset english_learning_method english_residence  \\\n",
       "0                  13.0                academic               usa   \n",
       "1                  14.0                academic               usa   \n",
       "2                  10.0                academic               usa   \n",
       "3                   6.0                academic               usa   \n",
       "4                  12.0                academic               usa   \n",
       "\n",
       "   length_of_english_residence   age  \n",
       "0                          2.0  26.0  \n",
       "1                          0.8  38.0  \n",
       "2                         14.0  43.0  \n",
       "3                          1.0  24.0  \n",
       "4                          2.0  31.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the native_bio_metadata.csv\n",
    "native_bio_metadata = pd.read_csv(NATIVE_FILE_PATH)\n",
    "native_bio_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language_num</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_language</th>\n",
       "      <th>english_residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mandarin1</td>\n",
       "      <td>female</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mandarin2</td>\n",
       "      <td>female</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mandarin3</td>\n",
       "      <td>male</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mandarin4</td>\n",
       "      <td>female</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mandarin5</td>\n",
       "      <td>female</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language_num     sex  native_language english_residence\n",
       "0    mandarin1  female  mandarin\\n(cmn)               usa\n",
       "1    mandarin2  female  mandarin\\n(cmn)               usa\n",
       "2    mandarin3    male  mandarin\\n(cmn)               usa\n",
       "3    mandarin4  female  mandarin\\n(cmn)               usa\n",
       "4    mandarin5  female  mandarin\\n(cmn)               usa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop href, age_sex, age_of_english_onset, other_languages, birthplace\n",
    "native_bio_metadata.drop(columns=['href', 'age', 'age_of_english_onset', 'other_languages', 'birth_place', 'age_sex', 'length_of_english_residence', 'english_learning_method'], inplace=True)\n",
    "native_bio_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language_num</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_language</th>\n",
       "      <th>english_residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1224</td>\n",
       "      <td>1224</td>\n",
       "      <td>1224</td>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1169</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>english578</td>\n",
       "      <td>female</td>\n",
       "      <td>english\\n(eng)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>635</td>\n",
       "      <td>604</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       language_num     sex native_language english_residence\n",
       "count          1224    1224            1224              1224\n",
       "unique         1169       2              27                 3\n",
       "top      english578  female  english\\n(eng)               usa\n",
       "freq              3     635             604              1031"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the native_bio_metadata\n",
    "native_bio_metadata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language_num</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_language</th>\n",
       "      <th>english_residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>english200</td>\n",
       "      <td>female</td>\n",
       "      <td>english\\n(eng)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>english123</td>\n",
       "      <td>female</td>\n",
       "      <td>english\\n(eng)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>english591</td>\n",
       "      <td>female</td>\n",
       "      <td>english\\n(eng)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>english86</td>\n",
       "      <td>male</td>\n",
       "      <td>english\\n(eng)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>english235</td>\n",
       "      <td>female</td>\n",
       "      <td>english\\n(eng)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>german15</td>\n",
       "      <td>male</td>\n",
       "      <td>german\\n(deu)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>portuguese61</td>\n",
       "      <td>female</td>\n",
       "      <td>portuguese\\n(por)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>french59</td>\n",
       "      <td>female</td>\n",
       "      <td>french\\n(fra)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>french84</td>\n",
       "      <td>female</td>\n",
       "      <td>french\\n(fra)</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>french25</td>\n",
       "      <td>male</td>\n",
       "      <td>french\\n(fra)</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      language_num     sex    native_language english_residence\n",
       "427     english200  female     english\\n(eng)               usa\n",
       "372     english123  female     english\\n(eng)               usa\n",
       "719     english591  female     english\\n(eng)               usa\n",
       "347      english86    male     english\\n(eng)               usa\n",
       "457     english235  female     english\\n(eng)               usa\n",
       "852       german15    male      german\\n(deu)               usa\n",
       "1024  portuguese61  female  portuguese\\n(por)               usa\n",
       "825       french59  female      french\\n(fra)               usa\n",
       "840       french84  female      french\\n(fra)               usa\n",
       "1122      french25    male      french\\n(fra)                uk"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove \\n and select first one in native_bio_metadata['english_residence']\n",
    "native_bio_metadata['english_residence'] = native_bio_metadata['english_residence'].apply(lambda x: x.split('\\n')[0])\n",
    "native_bio_metadata.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english_residence\n",
       "usa       1031\n",
       "uk         115\n",
       "canada      78\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value counts\n",
    "native_bio_metadata['english_residence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1224, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "native_bio_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to categorical function\n",
    "def to_categorical(y):\n",
    "    lang_dict = {}\n",
    "    for index, language in enumerate(set(y)):\n",
    "        lang_dict[language] = index\n",
    "    y = list(map(lambda x: lang_dict[x],y))\n",
    "    return keras.utils.to_categorical(y, len(lang_dict)), lang_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language_num</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_language</th>\n",
       "      <th>english_residence</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mandarin1</td>\n",
       "      <td>female</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>usa</td>\n",
       "      <td>data/audio/mandarin1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mandarin2</td>\n",
       "      <td>female</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>usa</td>\n",
       "      <td>data/audio/mandarin2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mandarin3</td>\n",
       "      <td>male</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>usa</td>\n",
       "      <td>data/audio/mandarin3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mandarin4</td>\n",
       "      <td>female</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>usa</td>\n",
       "      <td>data/audio/mandarin4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mandarin5</td>\n",
       "      <td>female</td>\n",
       "      <td>mandarin\\n(cmn)</td>\n",
       "      <td>usa</td>\n",
       "      <td>data/audio/mandarin5.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language_num     sex  native_language english_residence  \\\n",
       "0    mandarin1  female  mandarin\\n(cmn)               usa   \n",
       "1    mandarin2  female  mandarin\\n(cmn)               usa   \n",
       "2    mandarin3    male  mandarin\\n(cmn)               usa   \n",
       "3    mandarin4  female  mandarin\\n(cmn)               usa   \n",
       "4    mandarin5  female  mandarin\\n(cmn)               usa   \n",
       "\n",
       "                       file  \n",
       "0  data/audio/mandarin1.wav  \n",
       "1  data/audio/mandarin2.wav  \n",
       "2  data/audio/mandarin3.wav  \n",
       "3  data/audio/mandarin4.wav  \n",
       "4  data/audio/mandarin5.wav  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a new column 'file' with the full path of the audio file, the audio files are location in './data/native_combined/'\n",
    "native_bio_metadata.loc[:, 'file'] = native_bio_metadata['language_num'].apply(lambda x: f\"data/audio/{x}.wav\")\n",
    "native_bio_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english_residence\n",
       "usa       1031\n",
       "uk         115\n",
       "canada      78\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "native_bio_metadata['english_residence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform_audio(file):\n",
    "    audio,rate = torchaudio.load(str(file))\n",
    "    transform = torchaudio.transforms.Resample(rate,RATE_HZ)\n",
    "    audio = transform(audio).squeeze(0).numpy()\n",
    "    audio = audio[:MAX_LENGTH] # truncate to first part of audio to save RAM\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1224/1224 [00:15<00:00, 77.91it/s]\n"
     ]
    }
   ],
   "source": [
    "native_bio_metadata['audio'] = native_bio_metadata['file'].progress_apply(get_transform_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english_residence\n",
       "usa       1031\n",
       "uk         115\n",
       "canada      78\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "native_bio_metadata['english_residence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language_num</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_language</th>\n",
       "      <th>english_residence</th>\n",
       "      <th>file</th>\n",
       "      <th>audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>arabic179</td>\n",
       "      <td>male</td>\n",
       "      <td>arabic\\n(ars)</td>\n",
       "      <td>usa</td>\n",
       "      <td>data/audio/arabic179.wav</td>\n",
       "      <td>[-4.7082267e-06, -1.7670247e-05, -1.8126171e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>english146</td>\n",
       "      <td>male</td>\n",
       "      <td>english\\n(eng)</td>\n",
       "      <td>usa</td>\n",
       "      <td>data/audio/english146.wav</td>\n",
       "      <td>[0.0028268, 0.0045301947, 0.0040544877, 0.0043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>italian17</td>\n",
       "      <td>male</td>\n",
       "      <td>italian\\n(ita)</td>\n",
       "      <td>usa</td>\n",
       "      <td>data/audio/italian17.wav</td>\n",
       "      <td>[-0.0003382139, -0.0004581136, -0.0011106753, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>french73</td>\n",
       "      <td>male</td>\n",
       "      <td>french\\n(fra)</td>\n",
       "      <td>usa</td>\n",
       "      <td>data/audio/french73.wav</td>\n",
       "      <td>[-0.004545769, -0.0034042199, -0.0011074148, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>english398</td>\n",
       "      <td>female</td>\n",
       "      <td>english\\n(eng)</td>\n",
       "      <td>usa</td>\n",
       "      <td>data/audio/english398.wav</td>\n",
       "      <td>[0.0022351844, 0.004397306, 0.0042619184, 0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    language_num     sex native_language english_residence  \\\n",
       "270    arabic179    male   arabic\\n(ars)               usa   \n",
       "385   english146    male  english\\n(eng)               usa   \n",
       "883    italian17    male  italian\\n(ita)               usa   \n",
       "836     french73    male   french\\n(fra)               usa   \n",
       "569   english398  female  english\\n(eng)               usa   \n",
       "\n",
       "                          file  \\\n",
       "270   data/audio/arabic179.wav   \n",
       "385  data/audio/english146.wav   \n",
       "883   data/audio/italian17.wav   \n",
       "836    data/audio/french73.wav   \n",
       "569  data/audio/english398.wav   \n",
       "\n",
       "                                                 audio  \n",
       "270  [-4.7082267e-06, -1.7670247e-05, -1.8126171e-0...  \n",
       "385  [0.0028268, 0.0045301947, 0.0040544877, 0.0043...  \n",
       "883  [-0.0003382139, -0.0004581136, -0.0011106753, ...  \n",
       "836  [-0.004545769, -0.0034042199, -0.0011074148, -...  \n",
       "569  [0.0022351844, 0.004397306, 0.0042619184, 0.00...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "native_bio_metadata.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((979,), (245,), (979,), (245,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = native_bio_metadata['file'].values\n",
    "y = native_bio_metadata['english_residence'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Count: Counter({'usa': 825, 'uk': 92, 'canada': 62})\n",
      "Test Count: Counter({'usa': 206, 'uk': 23, 'canada': 16})\n"
     ]
    }
   ],
   "source": [
    "# create a counter for train and test labels\n",
    "train_counter = Counter(y_train)\n",
    "test_counter = Counter(y_test)\n",
    "\n",
    "print(f\"Train Count: {train_counter}\")\n",
    "print(f\"Test Count: {test_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat, _ = to_categorical(y_train)\n",
    "y_test_cat, lang_dict = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'usa': 0, 'uk': 1, 'canada': 2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 196608000000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 46\u001b[0m\n\u001b[0;32m     42\u001b[0m num_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# create a model\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTransformerModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlang_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# create a loss function\u001b[39;00m\n\u001b[0;32m     49\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "Cell \u001b[1;32mIn[28], line 9\u001b[0m, in \u001b[0;36mTransformerModel.__init__\u001b[1;34m(self, num_classes, num_features)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;241m=\u001b[39m num_classes\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features \u001b[38;5;241m=\u001b[39m num_features\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformerEncoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mTransformerEncoder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)\n",
      "File \u001b[1;32mc:\\Users\\musah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:560\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.__init__\u001b[1;34m(self, d_model, nhead, dim_feedforward, dropout, activation, layer_norm_eps, batch_first, norm_first, bias, device, dtype)\u001b[0m\n\u001b[0;32m    558\u001b[0m factory_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: device, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m: dtype}\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m \u001b[43mMultiheadAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Implementation of Feedforward model\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1 \u001b[38;5;241m=\u001b[39m Linear(d_model, dim_feedforward, bias\u001b[38;5;241m=\u001b[39mbias, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\musah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:999\u001b[0m, in \u001b[0;36mMultiheadAttention.__init__\u001b[1;34m(self, embed_dim, num_heads, dropout, bias, add_bias_kv, add_zero_attn, kdim, vdim, batch_first, device, dtype)\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_proj_weight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 999\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1000\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq_proj_weight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1001\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk_proj_weight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 196608000000 bytes."
     ]
    }
   ],
   "source": [
    "# create a transformer model for the training\n",
    "\n",
    "# transformer model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_classes, num_features):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = num_features\n",
    "        self.encoder = nn.TransformerEncoderLayer(d_model=self.num_features, nhead=8)\n",
    "        self.transformer = nn.TransformerEncoder(self.encoder, num_layers=6)\n",
    "        self.fc = nn.Linear(self.num_features, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "# create a dataset class\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio, rate = torchaudio.load(self.X[idx])\n",
    "        transform = torchaudio.transforms.Resample(rate, RATE_HZ)\n",
    "        audio = transform(audio).squeeze(0).numpy()\n",
    "        audio = audio[:MAX_LENGTH]\n",
    "        return audio, self.y[idx]\n",
    "    \n",
    "# create a dataloader\n",
    "train_dataset = AudioDataset(X_train, y_train_cat)\n",
    "test_dataset = AudioDataset(X_test, y_test_cat)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# get the number of features from the first batch shape\n",
    "num_features = next(iter(train_loader))[0].shape[1]\n",
    "\n",
    "\n",
    "# create a model\n",
    "model = TransformerModel(num_classes=len(lang_dict), num_features=num_features)\n",
    "\n",
    "# create a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create an optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# create a scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# train the model\n",
    "def train(model, train_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (audio, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(audio)\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:\n",
    "                print(f\"Epoch: {epoch+1}, Batch: {i+1}, Loss: {running_loss/10}\")\n",
    "                running_loss = 0.0\n",
    "        scheduler.step()\n",
    "    print(\"Training Finished\")\n",
    "    \n",
    "# train the model\n",
    "train(model, train_loader, criterion, optimizer, scheduler, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
